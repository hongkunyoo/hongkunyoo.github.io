---
layout: post
title:  "데이터 과학자를 위한 MLOps 툴"
date:   2021-01-27 00:00:00
categories: kubernetes mlops
image: /assets/images/jupyterflow/landing.png
---
지난 포스트 [데이터 과학자들은 쿠버네티스에 관심이 없습니다](https://coffeewhale.com/kubernetes/mlops/2021/01/28/mlops-determinedai)에 이어 제가 생각하는 좋은 해결책은 어떤 것인지에 대해 살펴 보도록 하겠습니다.

"데이터 과학자들은 쿠버네티스에 관심이 없습니다" 포스트의 내용을 정리하자면 다음과 같습니다.

- 쿠버네티스는 머신러닝을 효율적으로 수행하기 위한 좋은 툴이다.
- 하지만 데이터 과학자 입장에서는 사용하기가 불편하다. 쿠버네티스의 복잡한 개념을 전부 이해해야지만 제대로 사용할 수 있기 때문이다.
- 그래서 데이터 과학자가 분석에만 집중할 수 있는 사용하기 편리한 툴이 필요하다.

저도 100% 공감하는 내용이며 어떻게 하면 데이터 과학자가 쿠버네티스 기반의 ML 툴을 편리하게 사용할 수 있을까 고민을 하였고 오늘 저만의 해결책을 공유드리고자 합니다.

## 쿠버네티스 기반의 ML 툴을 사용하기 어려운 이유

지난 포스트에서도 다뤘지만 다시 한번 짚고 넘어가자면 쿠버네티스 기반의 ML툴, 대표적으로 Kubeflow와 같은 프레임워크를 사용할 때 데이터 과학자들이 느끼는 가장 큰 장벽은 아마도 자신의 코드를 **컨테이너화 시키는 부분**이라고 생각합니다.(도커 이미지 빌드 과정 및 실행)
주피터 노트북에서든, Rstudio에서든, VS code에서든, 윈도우에서든, 리눅스에서든 자신의 모델을 코드로 작성하는 일은 데이터 과학자 누구나 잘하는 일입니다. 문제는 자신의 코드를 학습서버 / 운영서버 위로 배포할 때 발생합니다.
쿠버네티스 기반의 플랫폼 위로 본인의 코드를 올리기 위해서는 컨테이너화라는 작업이 필요하게 됩니다. 이것은 개발자를 위한 과정이지 분석가를 위한 과정은 아닙니다. 그렇기 때문에 데이터 과학자 입장에서는 이러한 작업이 어색하게 느껴질 수 있습니다.
이를 해결하기 위해서 몇가지 방법들이 있습니다.

## 해결책

#### 1. 개발자들이 대신 작업해 준다.

데이터 과학자가 힘들어 하는 부분을 데이터 엔지니어, 소프트웨어 엔지니어가 도와주는 방법이 있을 수 있습니다. 하지만 개발자들도 본인들 본연의 역할들이 있기 때문에 이것은 지속 가능하지 않으며 전반적인 모델 개발 사이클을 늦추게 됩니다. 특히나 분석이라는 업무 자체가 기존 소프트웨어 개발과는 다르게 조금씩 코드를 수정해 보며 모델링 결과를 살펴봐야하는 경우가 많은데 그때마다 매번 다른 사람에게 종속성이 걸려 있으면 쉽게 지치게 됩니다.

#### 2. 교육을 통해 데이터 과학자들이 쿠버네티스를 직접 사용할 수 있게 한다.

앞선 포스트에서도 지적했듯이 모두가 유니콘이 될 수 없습니다. 그리고 단일 책임 원칙(Single-responsibility principle)에 따라 각자 잘하는 영역을 집중하는 것이 더 효율적일 수 있습니다.(물론 단일 책임 원칙은 사람에 대한 원칙이 아니라 프로그래밍 원칙이긴 하지만요.)

#### 3. 추상화를 통해 간편하게 사용할 수 있게 만들어 준다.

지난 포스트에서의 해결책으로 적절한 추상화를 통해 쿠버네티스의 복잡한 설정값을 숨겨 데이터 과학자가 일일이 알 필요 없이 모델링에 필요한 파라미터만을 신경 쓸 수 있도록 ML 툴을 개발하여 제공하는 것을 제안하였고 그 구현체로 Determined AI사에서 개발한 제품을 소개하였습니다.


## 커피고래가 제안하는 해결책

저는 비슷하지만 조금 다른 해결책을 제시합니다. 만약 다음과 같이 할 수 있다면 어떨까요?

### 컨테이너화 작업을 애초에 수행하지 않게 한다.

![이게무슨소리야](/assets/images/jupyterflow/meme.png)

앞서 설명드렸듯이 제가 생각하기에 쿠버네티스 기반의 ML툴을 사용하는 것의 가장 큰 장벽은 데이터 과학자들로 하여금 본인의 ML 코드를 **컨테이너화 시키도록 강제하는 작업**이라고 말씀드렸습니다. 그렇다면 이 작업을 아예 없앨 수는 없을까요?
여러분들은 제가 도대체 무슨 말도 안되는 소리를 하고 있냐고 의아해 하실 것 같습니다. [쿠버네티스 공식 홈페이지](https://kubernetes.io/)에 나오는 첫 문장이 "Production-Grade Container Orchestration"으로 컨테이너를 위한 오케스트레이션 플랫폼인 것을 명시하고 있습니다. 이런 플랫폼을 가져다 활용하는 마당에 컨테이너화 작업을 하지 않고도 데이터 과학자의 머신러닝 코드를 쿠버네티스 위해 실행할 수 있을까요?

제 생각은 **네, 가능합니다** 단지 한가지 제약 조건이 있습니다.

### 처음부터 컨테이너 내부에서 개발하면 됩니다.

이제 조금 더 자세하게 설명하겠습니다. 현재 문제는 데이터 과학자들이 **직접** 컨테이너화 작업을 수행해야 하며 이것이 쉽지 않은 작업이라는 것입니다. 그럼 미리 컨테이너화된 환경을 만들어서 데이터 과학자들에게 제공하는 것은 어떨까요? 그 안에서 데이터 과학자들이 본인의 코드를 개발하면 자연스럽게 데이터 과학자의 머신러닝 코드를 컨테이너에 탑재할 수 있지 않을까요? 그렇게 되면 손쉽게 쿠버네티스 위에 해당 컨테이너를 실행할 수 있을 것 같습니다. 근데 여기서 문제가 있습니다. 어떻게 미리 컨테이너화된 환경을 데이터 과학자들에게 손쉽게 제공할 수 있을까요?

### JupyterHub on Kubernetes

제가 찾은 해법은 주피터 허브에 있습니다. 주피터 허브는 여러 사용자가 각자 본인의 분석환경을 개별적으로 가질 수 있도록 제공해주는 플랫폼입니다. 주피터 허브를 구축하는 방법은 여러 가지가 있으나 제가 제시한 해결책은 [쿠버네티스 위에 주피터 허브를 배포하는 경우](https://zero-to-jupyterhub.readthedocs.io/en/latest/#setup-jupyterhub)에 한해서만 유효합니다. 앞으로 설명드리는 주피터 허브는 전부 이 쿠버네티스 기반의 주피터 허브에 대한 내용입니다.

주피터 허브의 아키텍처는 다음과 같습니다.

![주피터허브](/assets/images/jupyterflow/jupyterhub-arch.png)

사용자가 본인의 주피터 노트북을 런칭할 때마다 `Spawners`라는 녀석이 쿠버네티스 `Pod`를 하나씩 생성합니다. 이 `Pod` 하나는 주피터 노트북 서버 하나를 의미합니다. 사용자들은 저마다의 주피터 노트북 서버 하나씩을 배정 받아 그 안에서 모델 개발을 합니다. 각 `Pod`들은 전부 NAS 서버와 연결되어 주피터 노트북 서버에서 작성한 코드는 실제로 전부 NAS 서버로 저장이 됩니다. 

- `Pod` == 주피터 노트북 서버
- 데이터 저장은 NAS 서버로

이제 데이터 과학자는 이 주피터 노트북 서버에서 원하는대로 자유롭게 코딩을 합니다. 그렇게 되면 자연스럽게 ML 코드가 NAS 서버로 모입니다.

### 쿠버네티스 기반의 ML툴

어느 정도 모델 개발이 완료된 이후 쿠버네티스를 이용하여 여러 서버에 걸쳐 학습을 수행해 보고 싶은 단계가 되었습니다. 이때 필요한 정보는 크게 3가지입니다. "학습 실행환경, 머신러닝 소스코드, 모델 하이퍼파라미터"가 있습니다. 다음 학습 스크립트를 살펴 봅시다.

```bash
venv/bin/python train.py epoch=10 dropout=0.5
```

이때 각각의 요소는 다음과 같습니다.

- 학습 실행환경: `venv`
- 머신러닝 소스코드: `train.py`
- 모델 하이퍼파라미터: `epoch=10 dropout=0.5`

이러한 정보들을 어떻게든 쿠버네티스에게 전달하기만 하면 데이터 과학자들의 코드를 별도의 컨테이너화 작업 없이 바로 실행 시킬 수 있을 것입니다. 재밌게도 주피터 허브를 활용하면 이러한 정보들을 우리가 전부 알 수 있습니다.

![주피터허브](/assets/images/jupyterflow/newpod.png)

- 학습 실행환경: 주피터 노트북 서버에서 사용한 이미지
- 머신러닝 소스코드: NAS 서버에 저장된 모델 소스코드
- 모델 하이퍼파라미터: ML툴이 쿠버네티스로 전달

만약 **어떤 ML툴**이 똑똑하게도 데이터 과학자의 요청에 따라 자동으로 현재 사용하고 있는 학습 실행환경을 파악하고 방금 작성한 머신러닝 소스코드를 찾아 모델 하이퍼파라미터를 조합하여 YAML 파일을 작성한 후 쿠버네티스에 전달한다면 처음 제안드린 것과 같이 컨테이너화 작업 없이 데이터 과학자의 ML 코드를 쿠버네티스 위에서 실행할 수 있게 됩니다.

## JupyterFlow를 소개합니다.

정말 이런 ML툴이 존재할까요? 네, 여러분께 [JupyterFlow](https://jupyterflow.com)를 소개합니다.

![jupyterflow](https://raw.githubusercontent.com/hongkunyoo/jupyterflow/main/docs/images/architecture.png)

JupyterFlow는 편리한 머신러닝을 위한 CLI 툴로써 쿠버네티스용 주피터 노트북 서버에 실치만 하면 현재 데이터 과학자가 사용하고 있는 도커 이미지와 작성한 소스코드와 모델 하이퍼파라미터를 조합하여 쿠버네티스의 워크플로우로 생성해줍니다.
주피터 노트북에서 `hello.py`와 `world.py` 파일을 마음대로 작성하여 다음과 같이 실행하면 자동으로 쿠버네티스 워크플로우(Argo Workflow)를 실행해 줍니다.

```bash
jupyterflow run -c "python hello.py >> python world.py"
```

![](https://raw.githubusercontent.com/hongkunyoo/jupyterflow/main/docs/images/intro.png)


## 마치며

