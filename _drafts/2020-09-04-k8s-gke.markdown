---
layout: post
title:  "나만의 k8s 클러스터 구축하기 - #3 GCP GKE편"
date:   2020-09-04 00:00:00
categories: kubernetes cluster gke
image: /assets/images/k8s-cluster/landing03.png
---
이번 포스트에서는 GCP GKE를 이용하여 나만의 클러스터를 구축하는 방법에 대해 살펴보겠습니다.

1. [VirtualBox편](/kubernetes/cluster/virtualbox/2020/08/31/k8s-virtualbox/)
2. [Amazon EKS편](/kubernetes/cluster/eks/2020/09/03/k8s-eks/)
3. **GCP GKE편**

## 안내 사항

- GCP GKE는 클러스터 비용으로 시간당 $0.10, 워커 노드 비용으로 [GCE 비용](https://cloud.google.com/compute/vm-instance-pricing)이 청구되오니 유의하시기 바랍니다. 테스트 목적이라면 구축 후 바로 삭제하시기 바랍니다.
- GCP GKE 버전: 2020년 9월 현재, 기본 `1.15`를 사용합니다.

## 설치 방법

### 유저 등록

GCP 프로젝트에 유저를 등록하고 다음과 같은 역할을 부여합니다.

![](/assets/images/k8s-cluster/03-01.png)

- `Kubernetes Engine Admin`
- `Service Account User`

### 클러스터 생성

등록한 유저로 GCP 콘솔에 접속하여 우측 상단의 터미널 버튼을 클릭하여 Cloud Shell을 실행합니다.

![](/assets/images/k8s-cluster/03-02.png)

다음과 같은 명령을 이용하여 GKE 클러스터를 생성합니다.

```bash
CLUSTER_NAME=core-kubernetes
REGION=asia-northeast3-a

gcloud components update
gcloud config set compute/zone $REGION

gcloud container clusters create $CLUSTER_NAME \
    --enable-autoscaling \
    --min-nodes=1 \
    --num-nodes=1 \
    --max-nodes=3 \
    --node-locations=$REGION \
    --machine-type=n1-standard-4

# 클러스터 확인
kubectl get node
# NAME                                             STATUS   ROLES    AGE     VERSION
# gke-core-kubernetes-default-pool-b5dfd3f2-4f84   Ready    <none>   6m38s   v1.15.12-gke.2
```

### Cluster AutoScaler 설정

```bash
# GKE에는 기본적으로 metrics-server가 설치되어 있습니다.
kubectl get pod -nkube-system
# NAME                                                        READY   STATUS    RESTARTS   AGE
# event-exporter-v0.3.0-5cd6ccb7f7-p9869                      2/2     Running   0          6m31s
# fluentd-gcp-scaler-6855f55bcc-x4whf                         1/1     Running   0          6m26s
# fluentd-gcp-v3.1.1-vtw4j                                    2/2     Running   0          6m5s
# heapster-gke-7785454f49-t5782                               3/3     Running   0          5m47s
# kube-dns-5c446b66bd-q96j8                                   4/4     Running   0          6m32s
# kube-dns-autoscaler-6b7f784798-zbjj5                        1/1     Running   0          6m27s
# kube-proxy-gke-core-kubernetes-default-pool-b5dfd3f2-4f84   1/1     Running   0          6m23s
# l7-default-backend-84c9fcfbb-cjgms                          1/1     Running   0          6m32s
# metrics-server-v0.3.3-fdc67d4b6-vbfwt                       2/2     Running   0          6m11s
# prometheus-to-sd-vxz6k                                      2/2     Running   0          6m23s
# stackdriver-metadata-agent-cluster-level-5654d59f9-t4qdf    2/2     Running   0          5m54s


cat << EOF | kubectl apply -f -
# heavy-cal.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: heavy-cal
spec:
  selector:
    matchLabels:
      run: heavy-cal
  replicas: 1
  template:
    metadata:
      labels:
        run: heavy-cal
    spec:
      containers:
      - name: heavy-cal
        image: k8s.gcr.io/hpa-example
        ports:
        - containerPort: 80
        resources:
          limits:
            cpu: 500m
          requests:
            cpu: 300m
---
apiVersion: v1
kind: Service
metadata:
  name: heavy-cal
spec:
  ports:
  - port: 80
  selector:
    run: heavy-cal
EOF

# 별다른 설정 없이 바로 Pod의 개수를 늘려봅니다.
kubectl scale deployment heavy-cal --replicas=50
```

### EKS 클러스터 삭제

다음 명령을 이용하여 EKS 클러스터를 삭제하시기 바랍니다.

```bash
gcloud container clusters delete $CLUSTER_NAME
```

### 유저 삭제

GCP 콘솔을 접속하여 유저를 꼭 삭제합니다.

## 마치며
